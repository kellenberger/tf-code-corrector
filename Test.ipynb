{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sven/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "from batch_generators.java_batch_generator import JavaBatchGenerator\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = '/home/sven/java_github_corpus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project 0/14435\n",
      "project 1/14435\n",
      "project 2/14435\n",
      "project 3/14435\n",
      "project 4/14435\n",
      "project 5/14435\n",
      "project 6/14435\n",
      "project 7/14435\n",
      "project 8/14435\n",
      "project 9/14435\n",
      "project 10/14435\n",
      "project 11/14435\n",
      "project 12/14435\n",
      "project 13/14435\n",
      "project 14/14435\n",
      "project 15/14435\n",
      "project 16/14435\n",
      "project 17/14435\n",
      "project 18/14435\n",
      "project 19/14435\n",
      "project 20/14435\n",
      "project 21/14435\n",
      "project 22/14435\n",
      "project 23/14435\n",
      "project 24/14435\n",
      "project 25/14435\n",
      "project 26/14435\n",
      "project 27/14435\n",
      "project 28/14435\n",
      "project 29/14435\n",
      "project 30/14435\n",
      "project 31/14435\n",
      "project 32/14435\n",
      "project 33/14435\n",
      "project 34/14435\n",
      "project 35/14435\n",
      "project 36/14435\n",
      "project 37/14435\n",
      "project 38/14435\n",
      "project 39/14435\n",
      "project 40/14435\n",
      "project 41/14435\n",
      "project 42/14435\n",
      "project 43/14435\n",
      "project 44/14435\n",
      "project 45/14435\n",
      "project 46/14435\n",
      "project 47/14435\n",
      "project 48/14435\n",
      "project 49/14435\n",
      "project 50/14435\n",
      "project 51/14435\n",
      "project 52/14435\n",
      "project 53/14435\n",
      "project 54/14435\n",
      "project 55/14435\n",
      "project 56/14435\n",
      "project 57/14435\n",
      "project 58/14435\n",
      "project 59/14435\n",
      "project 60/14435\n",
      "project 61/14435\n",
      "project 62/14435\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import javalang\n",
    "\n",
    "subdirectories = [name for name in os.listdir(data_directory) if os.path.isdir(os.path.join(data_directory, name))]\n",
    "count = len(subdirectories)\n",
    "counter = Counter()\n",
    "for i, s in enumerate(subdirectories):\n",
    "    print('project {}/{}'.format(i, count))\n",
    "    files = [name for name in os.listdir(os.path.join(data_directory, s)) \n",
    "              if not os.path.isdir(os.path.join(data_directory, s, name))]\n",
    "    for file in files:\n",
    "        with open(os.path.join(data_directory, s, file), 'r') as file_data:\n",
    "            tokens = list(javalang.tokenizer.tokenize(file_data.read()))\n",
    "            counter.update(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_generator = JavaBatchGenerator(data_directory)\n",
    "input_iterator = batch_generator.train_batch_generator(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x, b, z = input_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "����������������������������������������������������;)\"pleh--  \"(nltnirp.tuo.metsyS\n",
      "���������������������������������������������������������������������������:tluafed\n",
      "������������������������������������������������������������������;)(nim regetnIgiB\n",
      "���������������������������������;\"EL\" = emaNnoitcirtseR gnirtS citats lanif cilbup\n",
      "���������������������������������������������������;teSrepapllaWsIm naeloob etavirp\n",
      "�������������������������������������������{ )sgra ][gnirtS(niam diov citats cilbup\n",
      "����������������������������������������������������������������������������������}\n",
      ";noitpecxEesraPatadateM sworht )mh >gnirtS ,gnirtS<paMhsaH(etadilav atadateMseliTbM\n",
      "[31, 8, 17, 50, 32, 40, 1, 83]\n"
     ]
    }
   ],
   "source": [
    "c = np.packbits(b, axis=2)\n",
    "for e in c:\n",
    "    s = ''\n",
    "    for f in e:\n",
    "        s += chr(f[0])\n",
    "    print(s)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([2**15], dtype='uint16')\n",
    "b = np.unpackbits(a.view('uint8'))\n",
    "print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 0. 0.]\n",
      " [1. 1. 1. 0.]]\n",
      "[[  1   2 128 128]\n",
      " [  3   4   5 128]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "target = tf.constant([[1,2,128,128],[3,4,5,128]], dtype=tf.int32)\n",
    "pad = tf.constant(128, dtype=tf.int32)\n",
    "b = tf.map_fn(lambda x: tf.map_fn(lambda y: tf.logical_not(tf.equal(y, pad)), x, dtype=tf.bool), target, dtype= tf.bool)\n",
    "           \n",
    "with tf.Session() as sess:\n",
    "    result = tf.to_float(b).eval()\n",
    "    print(result)\n",
    "    print(target.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1   2 128 128]\n",
      " [  3   4   5 128]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "target = tf.constant([[[1],[2],[128],[128]],[[3],[4],[5],[128]]], dtype=tf.int32)\n",
    "a = tf.reshape(target, [target.shape[0], target.shape[1]])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(a.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_size = 128\n",
    "batch_generator = 'Java' \n",
    "data_directory = data_directory\n",
    "num_layers = 2\n",
    "num_units = 256\n",
    "\n",
    "encoder_input = tf.placeholder(tf.int32, shape=(batch_size, None, 1), name='encoder_input')\n",
    "sequence_lengths = tf.placeholder(tf.int32, shape=(batch_size), name='sequence_lengths')\n",
    "decoder_input = tf.placeholder(tf.int32, shape=(batch_size, None, 1), name='decoder_input')\n",
    "target_output = tf.placeholder(tf.int32, shape=(batch_size, None), name='target_output')\n",
    "target_lengths = tf.placeholder(tf.int32, shape=(batch_size), name=\"target_lengths\")\n",
    "\n",
    "pad_code = tf.constant(128, dtype = tf.int32)\n",
    "\n",
    "target_weights = tf.to_int32(tf.map_fn(\n",
    "                                lambda x: tf.map_fn(\n",
    "                                            lambda y: tf.logical_not(tf.equal(y, pad_code)), \n",
    "                                            x, \n",
    "                                            dtype=tf.bool), \n",
    "                                target_output, \n",
    "                                dtype= tf.bool))\n",
    "\n",
    "if batch_generator == \"Java\":\n",
    "    batch_generator = JavaBatchGenerator(data_directory)\n",
    "elif batch_generator == \"Text\":\n",
    "    raise NotImplementedError(\"TextBatchGenerator is not implemented yet\")\n",
    "else:\n",
    "    raise ValueError(\"batch_generator argument not recognized; must be one of: \"\n",
    "                     \"Java, Text\")\n",
    "\n",
    "projection_layer = tf.layers.Dense(256, use_bias = False) # 256 characters can be represented in UTF-8\n",
    "\n",
    "encoder_layers = [tf.nn.rnn_cell.LSTMCell(num_units) for i in range(num_layers)]\n",
    "encoder_cell = tf.nn.rnn_cell.MultiRNNCell(encoder_layers)\n",
    "encoder_outputs, encoder_state = tf.nn.dynamic_rnn(cell = encoder_cell,\n",
    "                                                    inputs = tf.to_float(encoder_input),\n",
    "                                                    sequence_length = sequence_lengths,\n",
    "                                                    dtype = tf.float32)\n",
    "\n",
    "decoder_layers = [tf.nn.rnn_cell.LSTMCell(num_units) for i in range(num_layers)]\n",
    "decoder_cell = tf.nn.rnn_cell.MultiRNNCell(decoder_layers)\n",
    "helper = tf.contrib.seq2seq.TrainingHelper(tf.to_float(decoder_input), target_lengths)\n",
    "decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "    decoder_cell, helper, encoder_state,\n",
    "    output_layer=projection_layer)\n",
    "outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder)\n",
    "logits = outputs.rnn_output\n",
    "\n",
    "crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    labels=target_output, logits=logits)\n",
    "train_loss = (tf.reduce_sum(crossent * tf.to_float(target_weights)) / batch_size)\n",
    "\n",
    "tf.summary.FileWriter(\"/home/sven/logs\", tf.get_default_graph()).close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(ord(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
