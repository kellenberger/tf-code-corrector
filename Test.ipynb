{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sven/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import javalang\n",
    "\n",
    "from batch_generators.java_batch_generator import JavaBatchGenerator\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = '/home/sven/java_github_corpus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "a = tf.constant('  Hello World', dtype=tf.string)\n",
    "with tf.Session() as sess:\n",
    "    print(tf.size(tf.string_split([tf.py_func(lambda line: line.strip(), [a], tf.string)], '')).eval())\n",
    "    print(tf.size(tf.string_split([a], '')).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339\n"
     ]
    }
   ],
   "source": [
    "java_files = []\n",
    "\n",
    "with open(os.path.join(data_directory, 'trainJava.csv'), 'r') as train_projects:\n",
    "    for project in train_projects:\n",
    "        if os.path.exists(os.path.join(data_directory, project.strip())):\n",
    "            if len(java_files) > 100:\n",
    "                break\n",
    "            for subdir, _, files in os.walk(os.path.join(data_directory, project.strip())):\n",
    "                for file in files:\n",
    "                    java_files.append(os.path.join(data_directory, project.strip(), subdir, file))\n",
    "\n",
    "print(len(java_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[112  97  99 107  97 103 101  32 111 114 103  46 115 111 102 116 108  97\n",
      "  110 103  46  99 108 105 101 110 116  46  99 111 109 112  97 110 121  73\n",
      "  110 102 111  59]\n",
      " [105 109 112 111 114 116  32 106  97 118  97  46 105 111  46  83 101 114\n",
      "  105  97 108 105 122  97  98 108 101  59 128 128 128 128 128 128 128 128\n",
      "  128 128 128 128]]\n",
      "[[40]\n",
      " [28]]\n",
      "[[41]\n",
      " [29]]\n",
      "[[  0 112  97  99 107  97 103 101  32 111 114 103  46 115 111 102 116 108\n",
      "   97 110 103  46  99 108 105 101 110 116  46  99 111 109 112  97 110 121\n",
      "   73 110 102 111  59]\n",
      " [  0 105 109 112 111 114 116  32 106  97 118  97  46 105 111  46  83 101\n",
      "  114 105  97 108 105 122  97  98 108 101  59 128 128 128 128 128 128 128\n",
      "  128 128 128 128 128]]\n",
      "[[ 112   97   99  107   97  103  101   32  111  114  103   46  115  111\n",
      "   102  116  108   97  110  103   46   99  108  105  101  110  116   46\n",
      "    99  111  109  112   97  110  121   73  110  102  111   59 1000]\n",
      " [ 105  109  112  111  114  116   32  106   97  118   97   46  105  111\n",
      "    46   83  101  114  105   97  108  105  122   97   98  108  101   59\n",
      "  1000  128  128  128  128  128  128  128  128  128  128  128  128]]\n",
      "\n",
      "\n",
      "[[105 109 112 111 114 116  32 106  97 118  97  46 117 116 105 108  46  76\n",
      "  105 110 107 101 100  76 105 115 116  59]\n",
      " [105 109 112 111 114 116  32 106  97 118  97  46 117 116 105 108  46  76\n",
      "  105 115 116  59 128 128 128 128 128 128]]\n",
      "[[28]\n",
      " [22]]\n",
      "[[29]\n",
      " [23]]\n",
      "[[  0 105 109 112 111 114 116  32 106  97 118  97  46 117 116 105 108  46\n",
      "   76 105 110 107 101 100  76 105 115 116  59]\n",
      " [  0 105 109 112 111 114 116  32 106  97 118  97  46 117 116 105 108  46\n",
      "   76 105 115 116  59 128 128 128 128 128 128]]\n",
      "[[ 105  109  112  111  114  116   32  106   97  118   97   46  117  116\n",
      "   105  108   46   76  105  110  107  101  100   76  105  115  116   59\n",
      "  1000]\n",
      " [ 105  109  112  111  114  116   32  106   97  118   97   46  117  116\n",
      "   105  108   46   76  105  115  116   59 1000  128  128  128  128  128\n",
      "   128]]\n",
      "\n",
      "\n",
      "[[112 117  98 108 105  99  32  99 108  97 115 115  32  68 101 112 116  73\n",
      "  110 102 111  32 105 109 112 108 101 109 101 110 116 115  32  83 101 114\n",
      "  105  97 108 105 122  97  98 108 101  32 128 128 128 128 128 128 128 128\n",
      "  128 128 128 128 128 128 128 128 128 128 128 128]\n",
      " [112 114 105 118  97 116 101  32 115 116  97 116 105  99  32 102 105 110\n",
      "   97 108  32 108 111 110 103  32 115 101 114 105  97 108  86 101 114 115\n",
      "  105 111 110  85  73  68  32  61  32  51  55  54  49  53  52  56  51  51\n",
      "   56  48  57  50  48  53  50  48  52  54  76  59]]\n",
      "[[46]\n",
      " [66]]\n",
      "[[48]\n",
      " [67]]\n",
      "[[  0 112 117  98 108 105  99  32  99 108  97 115 115  32  68 101 112 116\n",
      "   73 110 102 111  32 105 109 112 108 101 109 101 110 116 115  32  83 101\n",
      "  114 105  97 108 105 122  97  98 108 101  32 123 128 128 128 128 128 128\n",
      "  128 128 128 128 128 128 128 128 128 128 128 128 128]\n",
      " [  0 112 114 105 118  97 116 101  32 115 116  97 116 105  99  32 102 105\n",
      "  110  97 108  32 108 111 110 103  32 115 101 114 105  97 108  86 101 114\n",
      "  115 105 111 110  85  73  68  32  61  32  51  55  54  49  53  52  56  51\n",
      "   51  56  48  57  50  48  53  50  48  52  54  76  59]]\n",
      "[[ 112  117   98  108  105   99   32   99  108   97  115  115   32   68\n",
      "   101  112  116   73  110  102  111   32  105  109  112  108  101  109\n",
      "   101  110  116  115   32   83  101  114  105   97  108  105  122   97\n",
      "    98  108  101   32  123 1000  128  128  128  128  128  128  128  128\n",
      "   128  128  128  128  128  128  128  128  128  128  128]\n",
      " [ 112  114  105  118   97  116  101   32  115  116   97  116  105   99\n",
      "    32  102  105  110   97  108   32  108  111  110  103   32  115  101\n",
      "   114  105   97  108   86  101  114  115  105  111  110   85   73   68\n",
      "    32   61   32   51   55   54   49   53   52   56   51   51   56   48\n",
      "    57   50   48   53   50   48   52   54   76   59 1000]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf8' codec can't decode byte 0xff in position 237: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-397aca27127f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sven/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sven/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sven/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sven/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1324\u001b[0;31m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1325\u001b[0m       \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBaseSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NODEDEF_NAME_RE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m       \u001b[0mnode_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sven/anaconda2/lib/python2.7/site-packages/tensorflow/python/util/compat.pyc\u001b[0m in \u001b[0;36mas_text\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbytes_or_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_or_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbytes_or_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected binary or unicode string, got %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbytes_or_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sven/anaconda2/lib/python2.7/encodings/utf_8.pyc\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(input, errors)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'strict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutf_8_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mIncrementalEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIncrementalEncoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf8' codec can't decode byte 0xff in position 237: invalid start byte"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = tf.data.Dataset.from_tensor_slices(java_files)\n",
    "\n",
    "def map_function(line):\n",
    "    def transform_string(s):\n",
    "        s = s.strip()\n",
    "        if random.random() > 0.9 and len(s) > 1:\n",
    "            brackets = ['(', ')', '[', ']', '{', '}']\n",
    "            bracket_indices = [i for i, c in enumerate(s) if c in brackets]\n",
    "            if bracket_indices:\n",
    "                drop_index = random.choice(bracket_indices)\n",
    "                s = s[:drop_index] + s[drop_index+1:]\n",
    "        if random.random() > 0.9 and len(s) > 1:\n",
    "            semicolon_indices = [i for i, c in enumerate(s) if c == ';']\n",
    "            if semicolon_indices:\n",
    "                drop_index = random.choice(semicolon_indices)\n",
    "                s = s[:drop_index] + s[drop_index+1:]\n",
    "        if random.random() > 0.9 and len(s) > 1:\n",
    "            change_char = random.randint(0, len(s)-2)\n",
    "            s = s[:change_char] + s[change_char+1] + s[change_char] + s[drop_char+2:]\n",
    "        return s\n",
    "        \n",
    "    t = tf.py_func(lambda string: string.strip(), [line], tf.string)\n",
    "    t = tf.map_fn(lambda elem:\n",
    "            tf.py_func(lambda char: np.array(ord(char), dtype=np.int32), [elem], tf.int32), tf.string_split([t], '').values, tf.int32)\n",
    "    dec_inp = tf.concat([[0], t], 0)\n",
    "    dec_out = tf.concat([t, [1000]], 0)\n",
    "    enc_inp = tf.py_func(transform_string, [line], tf.string)\n",
    "    enc_inp = tf.map_fn(lambda elem:\n",
    "            tf.py_func(lambda char: np.array(ord(char), dtype=np.int32), [elem], tf.int32), tf.string_split([enc_inp], '').values, tf.int32)\n",
    "    return enc_inp, tf.expand_dims(tf.size(enc_inp), 0), dec_inp, dec_out, tf.expand_dims(tf.size(dec_inp),0)\n",
    "\n",
    "dataset = dataset.flat_map(\n",
    "    lambda filename: (\n",
    "        tf.data.TextLineDataset(filename)\n",
    "        .filter(lambda line: \n",
    "                    tf.not_equal(\n",
    "                        tf.size(tf.string_split([tf.py_func(lambda l: l.strip(), [line], tf.string)],\"\")), \n",
    "                        tf.constant(0, dtype=tf.int32))\n",
    "               )\n",
    "    )\n",
    ")\n",
    "dataset = dataset.map(map_function)\n",
    "pad = tf.constant(128, dtype=tf.int32)\n",
    "dataset = dataset.apply(tf.contrib.data.padded_batch_and_drop_remainder(2, padded_shapes=([None], [1], [None], [None], [1]), \n",
    "                               padding_values=(pad, tf.constant(0, dtype=tf.int32), pad, pad, tf.constant(0, dtype=tf.int32))))\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "a = iterator.get_next()\n",
    "\n",
    "sess = tf.Session()\n",
    "for i in range(25):\n",
    "    z, b, c, d, e = sess.run(a)\n",
    "    print(z)\n",
    "    print(b)\n",
    "    print(e)\n",
    "    print(c)\n",
    "    print(d)\n",
    "    print(\"\\n\")\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 2 1]\n",
      " [6 5 4]]\n"
     ]
    }
   ],
   "source": [
    "a= tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.reverse(a, [1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1], [2], [3]])\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.reshape(a,[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([1,2,3])\n",
    "b = tf.random_uniform([1], minval = 0, maxval = tf.size(a))\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.concat([tf.slice(a, [0], b), tf.slice(a, b+1, tf.subtract(tf.size(a), b+1))], 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need more than 1 value to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-5e0d46359b8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdrop_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdrop_index\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.9\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0msemicolon_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m';'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msemicolon_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mdrop_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msemicolon_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need more than 1 value to unpack"
     ]
    }
   ],
   "source": [
    "s = 'System.out.println(\\\"Hello World\\\");'\n",
    "if random.random() > 0.9 and len(s) > 1:\n",
    "    brackets = ['(', ')', '[', ']', '{', '}']\n",
    "    bracket_indices = [i for i, c in s if c in brackets]\n",
    "    if bracket_indices:\n",
    "        drop_index = random.choice(bracket_indices)\n",
    "        s = s[:drop_index] + s[drop_index+1:]\n",
    "if random.random() > 0.9 and len(s) > 1:\n",
    "    semicolon_indices = [i for i, c in s if c == ';']\n",
    "    if semicolon_indices:\n",
    "        drop_index = random.choice(semicolon_indices)\n",
    "        s = s[:drop_index] + s[drop_index+1:]\n",
    "if random.random() > 0.9 and len(s) > 1:\n",
    "    drop_char = random.randint(0, len(s)-1)\n",
    "    s = s[:drop_char] + s[drop_char+1:]\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello' 'World']\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(['     Hello', 'World    '], dtype=tf.string)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.map_fn(lambda line: tf.py_func(lambda string: [s.strip() for s in string], [line], tf.string), [a], tf.string)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 5]\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3,4,5,6]\n",
    "b = random.sample(a, 2)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d978c0a3a03a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mchr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "for e in y:\n",
    "    s = ''\n",
    "    for f in e:\n",
    "        s += chr(f)\n",
    "    print(s)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([2**15], dtype='uint16')\n",
    "b = np.unpackbits(a.view('uint8'))\n",
    "print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 0. 0.]\n",
      " [1. 1. 1. 0.]]\n",
      "[[  1   2 128 128]\n",
      " [  3   4   5 128]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "target = tf.constant([[1,2,128,128],[3,4,5,128]], dtype=tf.int32)\n",
    "pad = tf.constant(128, dtype=tf.int32)\n",
    "b = tf.map_fn(lambda x: tf.map_fn(lambda y: tf.logical_not(tf.equal(y, pad)), x, dtype=tf.bool), target, dtype= tf.bool)\n",
    "           \n",
    "with tf.Session() as sess:\n",
    "    result = tf.to_float(b).eval()\n",
    "    print(result)\n",
    "    print(target.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensorValue(indices=array([[ 0,  0],\n",
      "       [ 0,  1],\n",
      "       [ 0,  2],\n",
      "       [ 0,  3],\n",
      "       [ 0,  4],\n",
      "       [ 0,  5],\n",
      "       [ 0,  6],\n",
      "       [ 0,  7],\n",
      "       [ 0,  8],\n",
      "       [ 0,  9],\n",
      "       [ 0, 10],\n",
      "       [ 0, 11],\n",
      "       [ 0, 12],\n",
      "       [ 0, 13],\n",
      "       [ 0, 14]]), values=array(['H', 'e', 'l', 'l', 'o', ' ', 'W', 'o', 'r', 'l', 'd', '\\n', 'Y',\n",
      "       'o', 'u'], dtype=object), dense_shape=array([ 1, 15]))\n",
      "['H' 'e' 'l' 'l' 'o' ' ' 'W' 'o' 'r' 'l' 'd' '\\n' 'Y' 'o' 'u']\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "a = tf.constant([\"Hello World\\nYou\"], dtype=tf.string)\n",
    "b = tf.string_split(a, delimiter='')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    c = b.eval()\n",
    "    print(c)\n",
    "    print(c.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_size = 128\n",
    "batch_generator = 'Java' \n",
    "data_directory = data_directory\n",
    "num_layers = 2\n",
    "num_units = 256\n",
    "\n",
    "encoder_input = tf.placeholder(tf.int32, shape=(batch_size, None, 1), name='encoder_input')\n",
    "sequence_lengths = tf.placeholder(tf.int32, shape=(batch_size), name='sequence_lengths')\n",
    "decoder_input = tf.placeholder(tf.int32, shape=(batch_size, None, 1), name='decoder_input')\n",
    "target_output = tf.placeholder(tf.int32, shape=(batch_size, None), name='target_output')\n",
    "target_lengths = tf.placeholder(tf.int32, shape=(batch_size), name=\"target_lengths\")\n",
    "\n",
    "pad_code = tf.constant(128, dtype = tf.int32)\n",
    "\n",
    "target_weights = tf.to_int32(tf.map_fn(\n",
    "                                lambda x: tf.map_fn(\n",
    "                                            lambda y: tf.logical_not(tf.equal(y, pad_code)), \n",
    "                                            x, \n",
    "                                            dtype=tf.bool), \n",
    "                                target_output, \n",
    "                                dtype= tf.bool))\n",
    "\n",
    "if batch_generator == \"Java\":\n",
    "    batch_generator = JavaBatchGenerator(data_directory)\n",
    "elif batch_generator == \"Text\":\n",
    "    raise NotImplementedError(\"TextBatchGenerator is not implemented yet\")\n",
    "else:\n",
    "    raise ValueError(\"batch_generator argument not recognized; must be one of: \"\n",
    "                     \"Java, Text\")\n",
    "\n",
    "projection_layer = tf.layers.Dense(256, use_bias = False) # 256 characters can be represented in UTF-8\n",
    "\n",
    "encoder_layers = [tf.nn.rnn_cell.LSTMCell(num_units) for i in range(num_layers)]\n",
    "encoder_cell = tf.nn.rnn_cell.MultiRNNCell(encoder_layers)\n",
    "encoder_outputs, encoder_state = tf.nn.dynamic_rnn(cell = encoder_cell,\n",
    "                                                    inputs = tf.to_float(encoder_input),\n",
    "                                                    sequence_length = sequence_lengths,\n",
    "                                                    dtype = tf.float32)\n",
    "\n",
    "decoder_layers = [tf.nn.rnn_cell.LSTMCell(num_units) for i in range(num_layers)]\n",
    "decoder_cell = tf.nn.rnn_cell.MultiRNNCell(decoder_layers)\n",
    "helper = tf.contrib.seq2seq.TrainingHelper(tf.to_float(decoder_input), target_lengths)\n",
    "decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "    decoder_cell, helper, encoder_state,\n",
    "    output_layer=projection_layer)\n",
    "outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder)\n",
    "logits = outputs.rnn_output\n",
    "\n",
    "crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    labels=target_output, logits=logits)\n",
    "train_loss = (tf.reduce_sum(crossent * tf.to_float(target_weights)) / batch_size)\n",
    "\n",
    "tf.summary.FileWriter(\"/home/sven/logs\", tf.get_default_graph()).close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(ord(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
